"""
Subprocess sandbox for safe code execution.

Runs user code (generated by the LLM) in an isolated subprocess with:
- Read-only access to the document context
- Mutable buffers/findings that persist across calls
- sub_query() function routed via TCP IPC to the parent process
- FINAL()/FINAL_VAR()/SHOW_VARS() built-in functions
- Timeout protection

This is the core security boundary of the RLM system â€” all LLM-generated
code runs here, never in the parent process.
"""

import json
import logging
import subprocess
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)


@dataclass
class SandboxResult:
    """Result from a sandbox code execution."""

    output: str = ""
    terminated: bool = False
    final_answer: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Backward compat: produce the same dict shape as v1."""
        return {
            "output": self.output,
            "terminated": self.terminated,
            "final_answer": self.final_answer,
        }


class Sandbox:
    """Stateless subprocess sandbox for code execution.

    Unlike the original ClaudeRLM._safe_run() which read state from self,
    this class receives everything as parameters, making it testable
    and reusable.

    Usage:
        sandbox = Sandbox(timeout=30)
        result = sandbox.execute(
            code='print(f"Context: {len(context)} chars")',
            context="document text...",
            buffers={},
            findings=[],
            ipc_port=12345,
        )
    """

    def __init__(self, timeout: int = 30):
        self.timeout = timeout

    def execute(
        self,
        code: str,
        context: str,
        buffers: Dict[str, Any],
        findings: List[Any],
        ipc_port: int,
    ) -> SandboxResult:
        """Execute code in a sandboxed subprocess.

        Args:
            code: Python code to execute (from LLM response).
            context: The document text available as `context` variable.
            buffers: Mutable dict persisted across calls.
            findings: Mutable list persisted across calls.
            ipc_port: Port for sub_query() IPC server.

        Returns:
            SandboxResult with output, termination status, and final answer.

        Side effects:
            buffers and findings dicts/lists are updated in-place with
            any modifications made by the subprocess.
        """
        # Write context to temp file
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".txt", delete=False
        ) as ctx_file:
            ctx_file.write(context)
            ctx_path = ctx_file.name

        # Write state to temp file
        state = {"buffers": buffers, "findings": findings}
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False
        ) as state_file:
            json.dump(state, state_file, default=str)
            state_path = state_file.name

        # Temp file for termination signal
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False
        ) as term_file:
            json.dump({"terminated": False}, term_file)
            term_path = term_file.name

        # Indent user code for try/except block
        indented = "\n".join("    " + line for line in code.splitlines())

        # Build wrapper script with real IPC-based sub_query
        wrapper = self._build_wrapper(
            ctx_path=ctx_path,
            state_path=state_path,
            term_path=term_path,
            ipc_port=ipc_port,
            indented_code=indented,
        )

        try:
            result = subprocess.run(
                ["python3", "-c", wrapper],
                capture_output=True,
                text=True,
                timeout=self.timeout,
            )

            output_parts = []
            if result.stdout:
                output_parts.append(result.stdout)
            if result.stderr:
                output_parts.append(f"STDERR: {result.stderr}")

            # Read back updated state
            try:
                with open(state_path, "r") as f:
                    updated_state = json.load(f)
                buffers.clear()
                buffers.update(updated_state.get("buffers", {}))
                findings.clear()
                findings.extend(updated_state.get("findings", []))
            except Exception:
                logger.debug("State file read failed, using defaults", exc_info=True)

            # Check for FINAL()/FINAL_VAR() termination
            try:
                with open(term_path, "r") as f:
                    term_state = json.load(f)
                if term_state.get("terminated"):
                    return SandboxResult(
                        output="\n".join(output_parts),
                        terminated=True,
                        final_answer=term_state.get("final_answer", ""),
                    )
            except Exception:
                logger.debug(
                    "Termination file read failed, assuming not terminated",
                    exc_info=True,
                )

            return SandboxResult(
                output="\n".join(output_parts) if output_parts else "",
                terminated=False,
                final_answer=None,
            )

        except subprocess.TimeoutExpired:
            return SandboxResult(
                output=f"Error: Code timed out after {self.timeout}s",
                terminated=False,
                final_answer=None,
            )
        finally:
            Path(ctx_path).unlink(missing_ok=True)
            Path(state_path).unlink(missing_ok=True)
            Path(term_path).unlink(missing_ok=True)

    @staticmethod
    def _build_wrapper(
        ctx_path: str,
        state_path: str,
        term_path: str,
        ipc_port: int,
        indented_code: str,
    ) -> str:
        """Build the subprocess wrapper script.

        This is the Python code that runs inside the subprocess. It sets up:
        - `context` variable from the temp file
        - `buffers` and `findings` from state file
        - `sub_query()` function via TCP IPC
        - `FINAL()`, `FINAL_VAR()`, `SHOW_VARS()` built-in functions
        - Error handling that writes termination state to temp file
        """
        return (
            "import json, re, sys, socket, struct\n"
            "\n"
            f"with open({ctx_path!r}, 'r') as f:\n"
            "    context = f.read()\n"
            "\n"
            f"with open({state_path!r}, 'r') as f:\n"
            "    _state = json.load(f)\n"
            "buffers = _state['buffers']\n"
            "findings = _state['findings']\n"
            "\n"
            "def sub_query(prompt, context_slice=None):\n"
            '    """Query a sub-LLM for targeted analysis. Makes a real API call."""\n'
            '    request = {"prompt": str(prompt), "context_slice": context_slice}\n'
            '    req_bytes = json.dumps(request).encode("utf-8")\n'
            f'    sock = socket.create_connection(("127.0.0.1", {ipc_port}), timeout=120)\n'
            "    try:\n"
            '        sock.sendall(struct.pack("!I", len(req_bytes)))\n'
            "        sock.sendall(req_bytes)\n"
            '        length_bytes = b""\n'
            "        while len(length_bytes) < 4:\n"
            "            chunk = sock.recv(4 - len(length_bytes))\n"
            "            if not chunk:\n"
            '                return "ERROR: Connection closed by server"\n'
            "            length_bytes += chunk\n"
            '        msg_len = struct.unpack("!I", length_bytes)[0]\n'
            '        data = b""\n'
            "        while len(data) < msg_len:\n"
            "            chunk = sock.recv(min(msg_len - len(data), 65536))\n"
            "            if not chunk:\n"
            "                break\n"
            "            data += chunk\n"
            '        response = json.loads(data.decode("utf-8"))\n'
            '        if "error" in response:\n'
            "            return f\"ERROR: {response['error']}\"\n"
            '        return response.get("result", "")\n'
            "    finally:\n"
            "        sock.close()\n"
            "\n"
            "def SHOW_VARS():\n"
            '    """Print all stored variables."""\n'
            '    print("=== STORED VARIABLES ===")\n'
            '    print(f"buffers ({len(buffers)} keys): {list(buffers.keys())}")\n'
            '    print(f"findings ({len(findings)} items)")\n'
            "    for k, v in buffers.items():\n"
            "        preview = str(v)[:200]\n"
            '        print(f"  buffers[{k!r}] = {preview}")\n'
            "    for i, f in enumerate(findings[:10]):\n"
            '        print(f"  findings[{i}] = {str(f)[:200]}")\n'
            "    if len(findings) > 10:\n"
            '        print(f"  ... and {len(findings) - 10} more findings")\n'
            "\n"
            "class _RLMTermination(Exception):\n"
            "    def __init__(self, answer):\n"
            "        self.answer = answer\n"
            "\n"
            "def FINAL(answer):\n"
            '    """Terminate the REPL loop and return this answer."""\n'
            "    raise _RLMTermination(str(answer))\n"
            "\n"
            "def FINAL_VAR(var_name):\n"
            '    """Terminate and return the value of a named variable."""\n'
            "    import __main__ as _m\n"
            "    _locals = {k: v for k, v in globals().items() if not k.startswith('_')}\n"
            "    val = _locals.get(var_name)\n"
            "    if val is None and var_name in dir(_m):\n"
            "        val = getattr(_m, var_name)\n"
            "    if val is None:\n"
            f'        raise _RLMTermination(f"ERROR: Variable {{var_name!r}} not found")\n'
            "    raise _RLMTermination(str(val))\n"
            "\n"
            "try:\n"
            f"{indented_code}\n"
            "except _RLMTermination as t:\n"
            f"    with open({term_path!r}, 'w') as f:\n"
            '        json.dump({"terminated": True, "final_answer": t.answer}, f)\n'
            "\n"
            f"with open({state_path!r}, 'w') as f:\n"
            '    json.dump({"buffers": buffers, "findings": findings}, f, default=str)\n'
        )
